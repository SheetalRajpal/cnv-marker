{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNjrXdjTZdMc"
      },
      "source": [
        "# First Phase-Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwuuKXDEcjYV"
      },
      "source": [
        "seed = 1030#,1,2,3,4,55,666,7777,88888,999999\n",
        "import random\n",
        "random.seed(seed)\n",
        "import numpy as np\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gc4Lt4bVGQk"
      },
      "source": [
        "#https://github.com/NeuroSyd/breast-cancer-sub-types\n",
        "#https://gitlab.cs.washington.edu/abdincer/ad-ae\n",
        "testPartitionIndex = 99"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsP2rDlcmjWi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/CNV')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb9LLtsam3lV"
      },
      "source": [
        "\"\"\"\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorflow_version 1\n",
        "#Start tensorboard\n",
        "%tensorboard â€” logdir logs\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCJdgXLZnHoQ"
      },
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import imp\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.models\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras import regularizers\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input,Dense,Dropout\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, Adadelta\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import keras.models as mod\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import TensorBoard\n",
        "#from sklearn.externals import joblib\n",
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGukEKjOnz03"
      },
      "source": [
        "\n",
        "np.random.seed(seed)\n",
        "df = pd.read_csv('./dataset/TCGA_BRCA_CNV.gz',compression='gzip',sep='\\t',index_col=0)\n",
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df=df.T\n",
        "print(\"CNV Matrix Before:\", df.shape)\n",
        "df2=pd.read_csv('./dataset/BRCA_clinicalMatrix.gz',compression='gzip',sep='\\t',index_col=0)\n",
        "print(\"Clinical Data Before:\", df2.shape)\n",
        "k=df2.columns.get_loc('PAM50Call_RNAseq')\n",
        "df2=df2[df2.iloc[:,k].isna()==False]             ########################3\n",
        "\n",
        "################see pam50 included...!!!! try including all\n",
        "\n",
        "\n",
        "###############################\n",
        "#df2=df2[df2.iloc[:,k]!='Normal']\n",
        "#d11=list(set(df.index)-set(df2.index)) #Comment this, if you want to test on unknown sample (generalize model)\n",
        "commonIndexes=list(set(df2.index).intersection(set(df.index))) \n",
        "df=df.loc[commonIndexes]\n",
        "df2=df2.loc[commonIndexes] \n",
        "#df=df.drop(d)                         #Comment this, if you want to test on unknown sample (generalize model)\n",
        "print(\"CNV After:\", df.shape)\n",
        "print(\"Clinical Data After:\", df2.shape)\n",
        "#print(\"Gene Expression and Clinical Data corresponds to same Patients: \", False if False in (df.index==df2.index) else True)\n",
        "######################unique_elements, counts_elements = np.unique(df2.iloc[:,k], return_counts=True)\n",
        "#################print(\"Labels\", unique_elements, counts_elements)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df<-1]"
      ],
      "metadata": {
        "id": "ErL5ZItbboGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A9zamSlAI-1"
      },
      "source": [
        "df.iloc[:,[2000]].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxsgwQgnyViH"
      },
      "source": [
        "X=np.array(df.values)\n",
        "#trainNoise = np.random.normal(loc=0.5, scale=0.5, size=trainX.shape)\n",
        "\n",
        "scaler=StandardScaler()\n",
        "XScaled=X#scaler.fit_transform(X)\n",
        "print(XScaled.mean(axis = 0), XScaled.std(axis = 0))\n",
        "\n",
        "\n",
        "################################33XScaled = X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.min(), X.max()"
      ],
      "metadata": {
        "id": "7z4ZiArnei1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqZIru2oBRJ3"
      },
      "source": [
        "plt.hist(XScaled[:,2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrecE4p9s4J0"
      },
      "source": [
        "#cols = [line.rstrip('\\n') for line in open('./testPartitions/test'+str(testPartitionIndex)+'.txt')] \n",
        "#ptest= [df.index.get_loc(c) for c in cols]       #When checking whether the model is working or not, uncomemnt\n",
        "ptest = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGkcMeHgpGKY"
      },
      "source": [
        "X.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRs0-eMBwPLW"
      },
      "source": [
        "X_test=XScaled[ptest,:]   #When checking whether the model is working or not, uncomemnt\n",
        "n  = X.shape[0]\n",
        "#X_test= np.asarray([])\n",
        "ptrain=list(set(range(n))-set(ptest))\n",
        "X_train=XScaled[ptrain,:]\n",
        "X_test.shape,X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJW5Ow0ohlei"
      },
      "source": [
        "Y_temp=np.array(df2.values[:,k])\n",
        "print(\"TARGET LABEL SIZE BEFORE: \", Y_temp.shape)\n",
        "label_encoder=LabelEncoder()\n",
        "Y=label_encoder.fit_transform(Y_temp)\n",
        "print(\"TARGET LABEL SIZE BEFORE: \", Y.shape)\n",
        "print(\"Labels before and after:\", Y_temp[0:9], Y[0:9])\n",
        "le_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(le_name_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1tC_jcohpVd"
      },
      "source": [
        "Y_train = Y.reshape(len(Y), 1)\n",
        "Y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siwq8ECvhqX6"
      },
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "sm = ADASYN(random_state=seed)\n",
        "\n",
        "#sm = SMOTE(random_state=seed)\n",
        "\n",
        "print('Train Set before SMOTE:', X_train.shape, Y_train.shape)\n",
        "\n",
        "\n",
        "X_train_sm, Y_train_sm = X_train, Y_train#sm.fit_resample(X_train, Y_train)\n",
        "print('Train Set after SMOTE:', X_train_sm.shape, Y_train_sm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RfMiIsIEQdi"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(Y_train, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz5XqRp-9Orr"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(Y_train_sm, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9SruIIHwpy8"
      },
      "source": [
        "\n",
        "input_dim=X_train.shape[1]\n",
        "encoding_dim=500\n",
        "\n",
        "\n",
        "# sample noise from a random normal distribution centered at 0.5 (since\n",
        "# our images lie in the range [0, 1]) and a standard deviation of 0.5\n",
        "\n",
        "# corrupted_input = salt_and_pepper(input=x, corruption_level=0.4)\n",
        "\n",
        "\n",
        "compression_factor=float(input_dim)/encoding_dim\n",
        "print(\"Compression factor: %s\" % compression_factor)\n",
        "\n",
        "input_layer1=Input(shape=(input_dim,),name='input')\n",
        "#hidden1=Dropout(0.0,name='dropout_100')(input_layer1)\n",
        "hidden2=Dense(5000,activation='relu',name='dense_100')(input_layer1)\n",
        "\n",
        "##################################################3hidden3=BatchNormalization(name='batch_normalization_100')(hidden2)#############33\n",
        "#hidden31=Dropout(0.0,name='dropout_101')(hidden3)\n",
        "hidden4=Dense(2000,activation='relu',name='dense_101')(hidden2)\n",
        "##########################################hidden5=BatchNormalization(name='batch_normalization_101')(hidden4)##################\n",
        "#hidden51=Dropout(0.0,name='dropout_102')(hidden5)\n",
        "hidden10=Dense(encoding_dim,activation='relu',name='dense_105')(hidden4)\n",
        "hidden7=BatchNormalization(name='batch_normalization_103')(hidden10) #############################3comment!!!!!\n",
        "#hidden12=Dropout(0.2,name='dropout_103')(hidden11)\n",
        "#hidden6=Dense(encoding_dim,activation='relu',name='dense_102')(hidden12)\n",
        "#hidden7=BatchNormalization(name='batch_normalization_102')(hidden10)\n",
        "#hidden13=Dense(500,activation='relu',name='dense_106')(hidden7)\n",
        "hidden8=Dense(2000,activation='relu',name='dense_103')(hidden7)\n",
        "hidden9=Dense(5000,activation='relu',name='dense_104')(hidden8)\n",
        "\n",
        "output1=Dense(input_dim,activation='linear',name='output')(hidden9)     #####################linear\n",
        "autoencoder=Model(inputs=input_layer1,outputs=output1)\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IzTev34uA2M"
      },
      "source": [
        "seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVWS2hizwByo"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 classes=np.unique(np.argmax(Y_train, axis=-1)),\n",
        "                                                y=np.argmax(Y_train, axis=-1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16lCO6_o8ckY"
      },
      "source": [
        "adam=Adam(lr=0.00002) #Change back to 0.00002\n",
        "autoencoder.compile(optimizer=adam, loss='mean_squared_error',metrics=['accuracy'])   ###try binary_crossentropy\n",
        "#es = EarlyStopping(monitor='val_loss', min_delta = 0.001, mode='min', verbose=1,patience=100)\n",
        "#tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1)\n",
        "numIterations = 300       #For unknown test data, set it to 300.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y82_oQ7vM3FL"
      },
      "source": [
        "history=autoencoder.fit(X_train_sm, X_train_sm,\n",
        "                epochs=numIterations,\n",
        "                batch_size=80, #80 ##################################################################3\n",
        "                shuffle=True#,  validation_split=0.0,   callbacks=[es] \n",
        "                )\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('Autoencoder Train loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "#plt.savefig('./Results/autoencoderTrainloss.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEuhtAny1nDx"
      },
      "source": [
        "B=autoencoder.predict(X_train)\n",
        "print(\"\\nTraining Error %s: %.5f\" % (autoencoder.metrics_names[1], (np.square(X_train-B)).mean(axis=None)))\n",
        "#B=autoencoder.predict(X_test)\n",
        "#print(\"\\nTesting Error %s: %.5f\" % (autoencoder.metrics_names[1], (np.square(X_test-B)).mean(axis=None)))\n",
        "# 1000, no dropout, no noise\n",
        "# Training Error accuracy: 0.00472\n",
        "# Testing Error accuracy: 0.00885\n",
        "# 2000, no dropout, no noise\n",
        "# Training Error accuracy: 0.00465\n",
        "# Testing Error accuracy: 0.00876 ##########################\n",
        "# 2000, droupout 0.2, BatchNormalization\n",
        "# Training Error accuracy: 0.00590\n",
        "# Testing Error accuracy: 0.01520\n",
        "# 2000, dropout 0, batchnormalization\n",
        "# Training Error accuracy: 0.00381\n",
        "# Testing Error accuracy: 0.01483\n",
        "#2000, dropout 0.2, batchnorm after only middle layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON9FKlXLJz2D"
      },
      "source": [
        "B[0:10], X_train[0:10] #Training Error accuracy: 0.01813"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAHk1sqDBhb2"
      },
      "source": [
        "B[0:10], X_train[0:10] #Training Error accuracy: 0.01813"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjaS1LiA7hLY"
      },
      "source": [
        "encoder=Model(inputs=input_layer1,outputs=hidden10)\n",
        "print(encoder.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4JAa1p97k0K"
      },
      "source": [
        "#Encoder9: Correct Dat Without BN\n",
        "#Encoder: BN after firsty two layers and not after 500!\n",
        "\n",
        " \n",
        "model_json=encoder.to_json()\n",
        "with open(\"./SavedModels/encoderBN\"+str(seed)+\".json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "encoder.save_weights(\"./SavedModels/encoderBN\"+str(seed)+\".h5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNOaGXWNvIUg"
      },
      "source": [
        "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}