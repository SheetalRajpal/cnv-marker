{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9VVQvMbSvns"
      },
      "source": [
        "# Phase 2: Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc2yk6dcY94M"
      },
      "outputs": [],
      "source": [
        "seed = 1030#,1,2,3,4,55,666,7777,88888,999999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJeVASKHQdrN"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/marcoancona/DeepExplain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bbmtmGqfER2"
      },
      "outputs": [],
      "source": [
        "!pip install kneed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIB-NSzlfFz_"
      },
      "outputs": [],
      "source": [
        "!pip install shap==0.31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3ifUTG9fHdE"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall h5py\n",
        "!pip install h5py==2.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR5v5FfgBHg7"
      },
      "outputs": [],
      "source": [
        "#!pip install git+https://github.com/albermax/innvestigate\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/CNV')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVOVQDq8fNX5"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "HGa6U73eZXJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HNFmU71aPHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print()"
      ],
      "metadata": {
        "id": "tDA-3_GRdDFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEYd5SE_BSXb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "\"\"\"\n",
        "%load_ext tensorboard\n",
        "%tensorflow_version 1\n",
        "#Start tensorboard\n",
        "%tensorboard â€” logdir logs\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gUoAAEvfSog"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "random.seed(seed)\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "#from tensorflow import set_random_seed\n",
        "#set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n2sqoT3YfuT"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade scikit-learn\n",
        "#!pip install --upgrade imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZRMaQFLXyQD"
      },
      "outputs": [],
      "source": [
        "#! pip install scikit-learn==0.21.1\n",
        "!pip install --upgrade scikit-learn\n",
        "! pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLjxKK3oBa2E"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline  \n",
        "import tensorflow as tf\n",
        "import imp\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import keras.backend\n",
        "import keras.models\n",
        "#import innvestigate\n",
        "#import innvestigate.utils as iutils\n",
        "#!pip install scikit-learn==0.20.0\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras import regularizers\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input,Dense,Dropout\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import keras.models as mod\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.utils.vis_utils import plot_model\n",
        "#from sklearn.externals import joblib\n",
        "import joblib\n",
        "drpRate = 0.55\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uusLuwkNBcQp"
      },
      "outputs": [],
      "source": [
        "#%tensorflow_version 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBxpPE7BnsZn"
      },
      "outputs": [],
      "source": [
        "#Initially 0\n",
        "np.random.seed(seed)\n",
        "df = pd.read_csv('./dataset/TCGA_BRCA_CNV.gz',compression='gzip',sep='\\t',index_col=0)\n",
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df=df.T\n",
        "print(\"CNV Matrix Before:\", df.shape)\n",
        "df2=pd.read_csv('./dataset/BRCA_clinicalMatrix.gz',compression='gzip',sep='\\t',index_col=0)\n",
        "print(\"Clinical Data Before:\", df2.shape)\n",
        "k=df2.columns.get_loc('PAM50Call_RNAseq')\n",
        "df2=df2[df2.iloc[:,k].isna()==False]\n",
        "#df2=df2[df2.iloc[:,k]!='Normal']\n",
        "#d11=list(set(df.index)-set(df2.index)) #Comment this, if you want to test on unknown sample (generalize model)\n",
        "commonIndexes=list(set(df2.index).intersection(set(df.index))) \n",
        "df=df.loc[commonIndexes]\n",
        "df2=df2.loc[commonIndexes] \n",
        "#df=df.drop(d)                         #Comment this, if you want to test on unknown sample (generalize model)\n",
        "print(\"CNV After:\", df.shape)\n",
        "print(\"Clinical Data After:\", df2.shape)\n",
        "print(\"CNV and Clinical Data corresponds to same Patients: \", False if False in (df.index==df2.index) else True)\n",
        "unique_elements, counts_elements = np.unique(df2.iloc[:,k], return_counts=True)\n",
        "print(\"Labels\", unique_elements, counts_elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKPMgZF8sFff"
      },
      "outputs": [],
      "source": [
        "X=np.array(df.values)\n",
        "scaler=StandardScaler()\n",
        "XScaled=X#scaler.fit_transform(X)\n",
        "print(XScaled.mean(axis = 0), XScaled.std(axis = 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQNLt718CJ0n"
      },
      "outputs": [],
      "source": [
        "#Encoding labels to numerical  values\n",
        "SampleIDs = np.array(df2.index )\n",
        "Y_temp=np.array(df2.values[:,k])\n",
        "print(\"TARGET LABEL SIZE BEFORE: \", Y_temp.shape)\n",
        "label_encoder=LabelEncoder()\n",
        "Y=label_encoder.fit_transform(Y_temp)\n",
        "print(\"TARGET LABEL SIZE BEFORE: \", Y.shape)\n",
        "print(\"Labels before and after:\", Y_temp[0:9], Y[0:9])\n",
        "le_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(le_name_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLmn2jV7EN88"
      },
      "outputs": [],
      "source": [
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "SampleIDs = SampleIDs.reshape(len(Y), 1)\n",
        "Y = Y.reshape(len(Y), 1)\n",
        "Y_onehot = onehot_encoder.fit_transform(Y)\n",
        "print(Y_onehot.shape, SampleIDs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmV9s-aq7f-G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Nlrbr3C9jx"
      },
      "outputs": [],
      "source": [
        "#sm=SMOTE(random_state=seed)\n",
        "from imblearn.over_sampling import ADASYN\n",
        "sm = ADASYN(random_state=seed)\n",
        "\n",
        "#X_train1, Y_train1 = X_train, Y_train\n",
        "#X_train, X_val,Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=seed) ##################3CHANGE####################################\n",
        "X_train1, Y_train1 = XScaled, Y_onehot\n",
        "X_train, X_val,Y_train, Y_val = X_train1, [],Y_train1, []     # train_test_split(X_train1, Y_train1, test_size = 0.10, random_state=seed, stratify=Y) ##################3CHANGE####################################\n",
        "sm=SMOTE(random_state=seed)\n",
        "X_train_res, Y_train_res= X_train, Y_train   #sm.fit_resample(X_train, Y_train)\n",
        "X_train_res.shape, Y_train_res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_XAyGUJhmWI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOqnL6QISjM-"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.models import model_from_json\n",
        "#json_file=open(\"./results/encoder.json\",'r')  #Remove fitted for generalized learning\n",
        "json_file=open(\"SavedModels/encoderBN\"+str(seed)+\".json\",'r')  #Remove fitted for generalized learning\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "encoder2 = model_from_json(loaded_model_json)  # for vae only: {'latent_dim': 500})\n",
        "# load weights into new model\n",
        "\n",
        "#encoder2.load_weights(\"./SavedModels/encoder.h5\")   #Remove fitted for generalized learning\n",
        "encoder2.load_weights(\"SavedModels/encoderBN\"+str(seed)+\".h5\")   #Remove fitted for generalized learning\n",
        "encoded_data_train=encoder2.predict(X_train_res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yNSjoxvD8oY"
      },
      "outputs": [],
      "source": [
        "plt.hist(encoded_data_train[:,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcfUk55UCwX1"
      },
      "outputs": [],
      "source": [
        "???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-reVVzxSZ1fE"
      },
      "outputs": [],
      "source": [
        "seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_7umar-DXbt"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Softmax\n",
        "\n",
        "drpRate1, drpRate2 = 0.4, 0.0 #### cahnge just made in july 2020 only for testing purpose\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "input_dim=encoded_data_train.shape[1]\n",
        "\n",
        "input_layer2=Input(shape=(input_dim,),name='inputNN')\n",
        "#hidden11=Dense(100,activation='relu')(input_layer2)\n",
        "#hidden13=Dense(250,activation='relu')(input_layer2)\n",
        "hidden132=BatchNormalization()(input_layer2)  #####################################no bn layer\n",
        "hidden12=Dropout(drpRate1, seed=seed)(hidden132)\n",
        "hidden14=Dense(200,activation='relu')(hidden12)##############################300\n",
        "########################################################################hidden132=BatchNormalization()(hidden14)  #remove leadto 72\n",
        "hidden15=Dropout(drpRate2)(hidden14)\n",
        "#hidden10=Dense(120,activation='relu')(hidden15)\n",
        "#hidden101=BatchNormalization()(hidden10)\n",
        "#hidden11=Dropout(drpRate)(hidden101)\n",
        "#hidden16=Dense(50,activation='relu')(hidden15)\n",
        "#########hidden17=Dense(25,activation='relu')(hidden15)#########################25\n",
        "#hidden162=BatchNormalization()(hidden16)\n",
        "#hidden161=Dropout(0.5)(hidden162)\n",
        "output2=Dense(5, name='outputNN')(hidden15)\n",
        "softmax = Softmax()(output2)\n",
        "classifier=Model(inputs=input_layer2, outputs=softmax)\n",
        "\n",
        "print(classifier.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12LJ5_36FfdQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 classes=np.unique(np.argmax(Y_train, axis=-1)),\n",
        "                                                y=np.argmax(Y_train, axis=-1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxwqXWeQkTWS"
      },
      "outputs": [],
      "source": [
        "adam=Adam(lr=0.00002)\n",
        "classifier.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "es = EarlyStopping(monitor='val_loss', min_delta = 0.001, mode='min', verbose=1,patience=250)    #best - 250\n",
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1)\n",
        "filepath=\"./SavedModels/weights-best\"+str(seed)+\".hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, save_weights_only=True, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Fit the model\n",
        "#model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, callbacks=callbacks_list, verbose=0)\n",
        "\n",
        "history=classifier.fit(encoded_data_train,Y_train_res,epochs=900,batch_size=64,shuffle=True,       #########################64  ->128(72 accuracy)\n",
        "                         #When checking whether the model is working or not, set the value to 0.1\n",
        "                     callbacks=[checkpoint])#, class_weight=class_weights)\n",
        "#classifier.load_weights(filepath)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNMnmTC4b-5r"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPNosyK9bv_j"
      },
      "outputs": [],
      "source": [
        "#0\n",
        "\n",
        "#without stratify-   97-78 0.0,       97, 79- 0.2\\\\\\\\//////\n",
        "#with stratify-      72,99      0.0 xxnormalxxin last:  75, 93 xxnormalxx  0.2 in last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTf2vx-GkTug"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl_cpr7yDo46"
      },
      "outputs": [],
      "source": [
        "# for reporting, report accuracy of x_train and not over sampled data\n",
        "# rerun  testval -> autoencoder2 -> subtype\n",
        "score=classifier.evaluate(encoded_data_train,Y_train_res)\n",
        "print(\"\\nTraining Accuracy %s: %.2f%%\" % (classifier.metrics_names[1], score[1]*100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zXPTJyRydIH"
      },
      "outputs": [],
      "source": [
        "encoded_data=encoder2.predict(X_train1)\n",
        "y_pred=classifier.predict(encoded_data)\n",
        "y_pred=np.argmax(y_pred,axis=-1).reshape(-1,1)\n",
        "y_true=np.argmax(Y_train1,axis=-1).reshape(-1,1)\n",
        "#y_pred.shape,y_true.shape\n",
        "cm=confusion_matrix(y_pred,y_true)\n",
        "cm.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd-42vhV_k_C"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install mlxtend --upgrade --no-deps \n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import numpy as np\n",
        "plt.figure()\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm.T,\n",
        "                                colorbar=True,\n",
        "                                show_absolute=True,\n",
        "                                show_normed=True, class_names = ['Basal', 'Her2', 'LumA', 'LumB', 'Normal'])\n",
        "#plt.show()\n",
        "#plt.savefig('/content/drive/My Drive/BRCA/CMPhase1.png', bbox_inches = 'tight', dpi = 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xpTcqvWF79N"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fbhc1Tl8GltF"
      },
      "outputs": [],
      "source": [
        "classifier.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbYdgeqjEpqv"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_data = Input(shape=(24776,))\n",
        "\n",
        "encoder_layer1=encoder2.layers[1]\n",
        "encoder_layer2=encoder2.layers[2]\n",
        "encoder_layer3=encoder2.layers[3]\n",
        "\n",
        "\n",
        "#encoder_layer6=encoder2.layers[6]\n",
        "\n",
        "\n",
        "encoder_layer13 = classifier.layers[1]\n",
        "encoder_layer14 = classifier.layers[2]\n",
        "encoder_layer15 = classifier.layers[3]\n",
        "encoder_layer16 = classifier.layers[4]\n",
        "encoder_layer17 = classifier.layers[5]\n",
        "encoder_layer18 = classifier.layers[6]\n",
        "#encoder_layer19 = classifier.layers[7]\n",
        "\n",
        "\n",
        "\n",
        "encoder = Model(input_data, encoder_layer17(encoder_layer16(encoder_layer15(encoder_layer14(encoder_layer13(encoder_layer3(encoder_layer2(encoder_layer1(input_data)))))))))\n",
        "#encoderTemp= Model(input_data, encoder_layer17(encoder_layer16(encoder_layer15(encoder_layer14(encoder_layer13(encoder_layer5(encoder_layer4(encoder_layer3(encoder_layer2(encoder_layer1(input_data)))))))))))\n",
        "\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "169aVfeIEnpq"
      },
      "outputs": [],
      "source": [
        "final=encoder\n",
        "final_json=final.to_json()\n",
        "with open(\"./models/CombinedModel_Seed\"+str(seed)+\".json\",\"w\") as json_file:\n",
        "  json_file.write(final_json)\n",
        "\n",
        "final.save_weights(\"./models/CombinedModel_Seed\"+str(seed)+\".h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJEXw_ARBTGp"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqwnBu-EHNhl"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "with open(\"./models/CombinedModel_Seed\"+str(seed)+\".json\", 'r') as json_file:\n",
        "    encoder= json_file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4Bz78afHQk2"
      },
      "outputs": [],
      "source": [
        "encoder = keras.models.model_from_json(encoder)\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCH2IY9tHU14"
      },
      "outputs": [],
      "source": [
        "encoder.load_weights(\"./models/CombinedModel_Seed\"+str(seed)+\".h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu7eC2wRHWzw"
      },
      "outputs": [],
      "source": [
        "encoder.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S93dt6frHaI5"
      },
      "outputs": [],
      "source": [
        "seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BFqGUMCmW10"
      },
      "source": [
        "##################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf. __version__"
      ],
      "metadata": {
        "id": "nVtTfucgrtxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEo6jr_70eLR"
      },
      "outputs": [],
      "source": [
        "XScaled, Y_onehot = X_train, Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SPr378mHc4f"
      },
      "outputs": [],
      "source": [
        "from kneed import KneeLocator\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['agg.path.chunksize'] = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxOlXCwAHe1h"
      },
      "outputs": [],
      "source": [
        "encoder.layers[-2]._inbound_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUggzhT-LKoM"
      },
      "outputs": [],
      "source": [
        "zero_pos_counter = {\n",
        "    'deeplift Basal' : 0,\n",
        "    'intgrad Basal' : 0,\n",
        "    'grad*input Basal' : 0,\n",
        "    'elrp Basal' : 0,\n",
        "    'gradshap Basal': 0,\n",
        "    'deepshap Basal' : 0,\n",
        "\n",
        "    'deeplift Her2' : 0,\n",
        "    'intgrad Her2' : 0,\n",
        "    'grad*input Her2' : 0,\n",
        "    'elrp Her2' : 0,\n",
        "    'gradshap Her2': 0,\n",
        "    'deepshap Her2' : 0,\n",
        "\n",
        "    'deeplift LumA' : 0,\n",
        "    'intgrad LumA' : 0,\n",
        "    'grad*input LumA' : 0,\n",
        "    'elrp LumA' : 0,\n",
        "    'gradshap LumA': 0,\n",
        "    'deepshap LumA' : 0,\n",
        "\n",
        "    'deeplift LumB' : 0,\n",
        "    'intgrad LumB' : 0,\n",
        "    'grad*input LumB' : 0,\n",
        "    'elrp LumB' : 0,\n",
        "    'gradshap LumB': 0,\n",
        "    'deepshap LumB' : 0,\n",
        "\n",
        "    'deeplift Normal' : 0,\n",
        "    'intgrad Normal' : 0,\n",
        "    'grad*input Normal' : 0,\n",
        "    'elrp Normal' : 0,\n",
        "    'gradshap Normal': 0,\n",
        "    'deepshap Normal' : 0, \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blRJTf8mMjT_"
      },
      "outputs": [],
      "source": [
        "zero_neg_counter = {\n",
        "    'deeplift Basal' : 0,\n",
        "    'intgrad Basal' : 0,\n",
        "    'grad*input Basal' : 0,\n",
        "    'elrp Basal' : 0,\n",
        "    'gradshap Basal': 0,\n",
        "    'deepshap Basal' : 0,\n",
        "\n",
        "    'deeplift Her2' : 0,\n",
        "    'intgrad Her2' : 0,\n",
        "    'grad*input Her2' : 0,\n",
        "    'elrp Her2' : 0,\n",
        "    'gradshap Her2': 0,\n",
        "    'deepshap Her2' : 0,\n",
        "\n",
        "    'deeplift LumA' : 0,\n",
        "    'intgrad LumA' : 0,\n",
        "    'grad*input LumA' : 0,\n",
        "    'elrp LumA' : 0,\n",
        "    'gradshap LumA': 0,\n",
        "    'deepshap LumA' : 0,\n",
        "\n",
        "    'deeplift LumB' : 0,\n",
        "    'intgrad LumB' : 0,\n",
        "    'grad*input LumB' : 0,\n",
        "    'elrp LumB' : 0,\n",
        "    'gradshap LumB': 0,\n",
        "    'deepshap LumB' : 0,\n",
        "\n",
        "    'deeplift Normal' : 0,\n",
        "    'intgrad Normal' : 0,\n",
        "    'grad*input Normal' : 0,\n",
        "    'elrp Normal' : 0,\n",
        "    'gradshap Normal': 0,\n",
        "    'deepshap Normal' : 0, \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vJ1g0sS_LeP"
      },
      "outputs": [],
      "source": [
        "sensitivity = 0.9#1e-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjQusU72HnWQ"
      },
      "outputs": [],
      "source": [
        "sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-mwJH_FLKSN"
      },
      "outputs": [],
      "source": [
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPii_sy7Mnhe"
      },
      "outputs": [],
      "source": [
        "XScaled.shape, Y_onehot.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "KUdtSwj5tq_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8LKlt_wHgbG"
      },
      "outputs": [],
      "source": [
        "from deepexplain.tensorflow import DeepExplain\n",
        "from collections import Counter\n",
        "model = encoder\n",
        "for method in ['deeplift', 'elrp', 'grad*input',  'intgrad']:#, 'saliency']:  \n",
        "          \n",
        "          with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
        "              #model\n",
        "              input_tensor = model.layers[0].input\n",
        "              fModel = Model(inputs=input_tensor, outputs = model.layers[-1].output)\n",
        "              target_tensor = fModel(input_tensor) \n",
        "              for i,subtype in enumerate(['Basal', 'Her2', 'LumA', 'LumB', 'Normal']):\n",
        "                      IG={}\n",
        "                      mask = Y_onehot[:,i]==1\n",
        "                      xs = XScaled[mask]\n",
        "                      ys = Y_onehot[mask]\n",
        "                      \n",
        "                      attributions_ig= de.explain(method, target_tensor, input_tensor, xs, ys=ys)\n",
        "                      \n",
        "                      data=np.asarray(attributions_ig)\n",
        "                      data1 = pd.DataFrame(data, columns=df.columns)\n",
        "                      \n",
        "                      genes_union_pos, genes_union_neg = [], []\n",
        "                      for index, row in data1.iterrows():\n",
        "                                                 \n",
        "                        pos = row[row > 0]\n",
        "                        neg = row[row < 0]*-1\n",
        "                        \n",
        "                        indexes=np.argsort(pos)[::-1]\n",
        "                        genespos=pos.index[indexes]\n",
        "                        relpos=pos.iloc[indexes]\n",
        "                        if len(relpos) > 1:\n",
        "                          kneedle_pos = KneeLocator(range(len(relpos)), relpos,   curve=\"convex\", direction=\"decreasing\") #  \n",
        "                          if kneedle_pos.knee is not None:\n",
        "                            pos_knee = kneedle_pos.knee\n",
        "                          else:\n",
        "                            pos_knee = 0\n",
        "                            zero_pos_counter[method+' '+subtype] += 1\n",
        "                        elif len(relpos) == 1:\n",
        "                          pos_knee = 1\n",
        "                        else:\n",
        "                          zero_pos_counter[method+' '+subtype] += 1\n",
        "                          pos_knee = 0\n",
        "                        \n",
        "                        indexes=np.argsort(neg)[::-1]\n",
        "                        genesneg=neg.index[indexes]\n",
        "                        relneg=neg.iloc[indexes]\n",
        "                        if len(relneg) > 1:\n",
        "                          kneedle_neg = KneeLocator(range(len(relneg)), relneg,   curve=\"convex\", direction=\"decreasing\")\n",
        "                          if kneedle_neg.knee is not None:\n",
        "                            neg_knee = kneedle_neg.knee\n",
        "                          else:\n",
        "                            neg_knee = 0\n",
        "                            zero_neg_counter[method+' '+subtype] += 1\n",
        "                        elif len(relneg) == 1:\n",
        "                          neg_knee = 1\n",
        "                        else:\n",
        "                          zero_neg_counter[method+' '+subtype] += 1\n",
        "                          neg_knee = 0\n",
        "                        \n",
        "                        #kneedle_pos.plot_knee()\n",
        "                        #print(kneedle_pos.knee, kneedle_neg.knee)\n",
        "                        #kneedle_neg.plot_knee()\n",
        "                                                \n",
        "                        genes_union_pos.extend(list(relpos.head(pos_knee).index))\n",
        "                        genes_union_neg.extend(list(relneg.head(neg_knee).index))\n",
        "                        \n",
        "\n",
        "                      genes_count_pos = dict(Counter(genes_union_pos))\n",
        "                      genes_count_neg = dict(Counter(genes_union_neg))\n",
        "\n",
        "                      freq_pos = dict(sorted(genes_count_pos.items(), key=lambda item: item[1], reverse=True))\n",
        "                      freq_df_pos = pd.DataFrame(freq_pos.items(), columns=[subtype+'Genes', 'Frequency'])\n",
        "                      freq_neg = dict(sorted(genes_count_neg.items(), key=lambda item: item[1], reverse=True))\n",
        "                      freq_df_neg = pd.DataFrame(freq_neg.items(), columns=[subtype+'Genes', 'Frequency'])\n",
        "                     \n",
        "                      final_pos = freq_df_pos  #[freq_df_pos['Frequency'] >= round(data1.shape[0]*.2)]\n",
        "                      print(method, subtype, final_pos.shape, 'pos')\n",
        "                      final_neg = freq_df_neg  #[freq_df_neg['Frequency'] >= round(dat  `a1.shape[0]*.2)]\n",
        "                      print(method, subtype, final_neg.shape, 'neg')\n",
        "\n",
        "                      final_pos.to_csv('./Attributions68NoNORMDRP0 Patientwise/seed'+str(seed)+'/'+method+'_'+str(subtype)+'_pos.csv')\n",
        "                      final_neg.to_csv('./Attributions68NoNORMDRP0 Patientwise/seed'+str(seed)+'/'+method+'_'+str(subtype)+'_neg.csv')\n",
        "                      \n",
        "              #bottom100.T.plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW7WtfrJ3pzN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}